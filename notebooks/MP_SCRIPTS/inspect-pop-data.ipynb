{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Generated Zonal Stats\n",
    "This notebook will run through a checks to see if the generated h3 zonal stats have been calculated correctly. This will include checking at the following steps:\n",
    "\n",
    "1. H1 CSV files on S3\n",
    "2. Aggregated parquet files on S3\n",
    "3. S2S database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from geojson_pydantic import Feature, Polygon\n",
    "#from lonboard import Map, ScatterplotLayer\n",
    "from shapely import from_geojson\n",
    "\n",
    "from space2stats import StatsTable\n",
    "\n",
    "from shapely.geometry import shape\n",
    "import requests\n",
    "import json\n",
    "#import folium as flm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input variables\n",
    "iso3 = 'KEN'\n",
    "ADM = \"ADM0\"\n",
    "s3_csv_file = 's3://wbg-geography01/Space2Stats/h3_stats_data/GLOBAL/Urbanization_Pop/815b3ffffffffff/GHS_POP_2020_Urban_Breakdown.csv'\n",
    "s3_parquet_file = 's3://wbg-geography01/Space2Stats/parquet/GLOBAL/NTL_VIIRS_LEN_2012_combined.parquet'\n",
    "s2s_fields = ['']\n",
    "\n",
    "\n",
    "# Fetch the admin boundaries and convert to geojson\n",
    "def fetch_admin_boundaries(iso3: str, adm: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"Fetch administrative boundaries from GeoBoundaries API.\"\"\"\n",
    "    url = f\"https://www.geoboundaries.org/api/current/gbOpen/{iso3}/{adm}/\"\n",
    "    res = requests.get(url).json()\n",
    "    return gpd.read_file(res[\"gjDownloadURL\"])\n",
    "\n",
    "adm_boundaries = fetch_admin_boundaries(iso3, ADM)\n",
    "geojson_str = adm_boundaries.to_json()\n",
    "adm_geojson = json.loads(geojson_str)\n",
    "adm_features = adm_geojson[\"features\"]\n",
    "feature = adm_features[0]\n",
    "\n",
    "# Read in the environment variables \n",
    "load_dotenv(\"../../db.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'h3' has no attribute 'polyfill'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m StatsTable\u001b[38;5;241m.\u001b[39mconnect() \u001b[38;5;28;01mas\u001b[39;00m stats_table:\n\u001b[1;32m----> 2\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mstats_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummaries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43maoi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspatial_join_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtouches\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpolygon\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m     10\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\wbg\\Anaconda3\\envs\\s2s\\Lib\\site-packages\\space2stats\\lib.py:77\u001b[0m, in \u001b[0;36mStatsTable.summaries\u001b[1;34m(self, aoi, spatial_join_method, fields, geometry)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Get H3 ids from geometry\u001b[39;00m\n\u001b[0;32m     76\u001b[0m resolution \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[1;32m---> 77\u001b[0m h3_ids \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_h3_ids\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43maoi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspatial_join_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m h3_ids:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "File \u001b[1;32mc:\\wbg\\Anaconda3\\envs\\s2s\\Lib\\site-packages\\space2stats\\h3_utils.py:109\u001b[0m, in \u001b[0;36mgenerate_h3_ids\u001b[1;34m(aoi_geojson, resolution, spatial_join_method)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m geom \u001b[38;5;129;01min\u001b[39;00m aoi_shape\u001b[38;5;241m.\u001b[39mgeoms:\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;66;03m# Convert each geometry to GeoJSON\u001b[39;00m\n\u001b[0;32m    107\u001b[0m         geom_geojson \u001b[38;5;241m=\u001b[39m mapping(geom)\n\u001b[0;32m    108\u001b[0m         h3_ids\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m--> 109\u001b[0m             \u001b[43m_generate_h3_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeom_geojson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_join_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m         )\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# Single polygon case\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     h3_ids \u001b[38;5;241m=\u001b[39m _generate_h3_ids(aoi_geojson, resolution, spatial_join_method)\n",
      "File \u001b[1;32mc:\\wbg\\Anaconda3\\envs\\s2s\\Lib\\site-packages\\space2stats\\h3_utils.py:71\u001b[0m, in \u001b[0;36m_generate_h3_ids\u001b[1;34m(aoi_geojson, resolution, spatial_join_method)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid spatial join method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspatial_join_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Generate H3 hexagons covering the AOI\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Polyfill defines containment based on centroid:\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# https://h3geo.org/docs/3.x/api/regions/#polyfill\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m h3_ids \u001b[38;5;241m=\u001b[39m \u001b[43m_recursive_polyfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43maoi_geojson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spatial_join_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithin\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     74\u001b[0m     h3_ids \u001b[38;5;241m=\u001b[39m _find_within(aoi_geojson, h3_ids)\n",
      "File \u001b[1;32mc:\\wbg\\Anaconda3\\envs\\s2s\\Lib\\site-packages\\space2stats\\h3_utils.py:14\u001b[0m, in \u001b[0;36m_recursive_polyfill\u001b[1;34m(aoi_geojson, resolution, original_resolution)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recursive_polyfill\u001b[39m(\n\u001b[0;32m     11\u001b[0m     aoi_geojson: Dict[\u001b[38;5;28mstr\u001b[39m, Any], resolution: \u001b[38;5;28mint\u001b[39m, original_resolution: \u001b[38;5;28mint\u001b[39m\n\u001b[0;32m     12\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Set[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Attempt to get H3 IDs at the current resolution\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     h3_ids \u001b[38;5;241m=\u001b[39m \u001b[43mh3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolyfill\u001b[49m(aoi_geojson, resolution, geo_json_conformant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# If valid H3 IDs are found, return them\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m h3_ids:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'h3' has no attribute 'polyfill'"
     ]
    }
   ],
   "source": [
    "with StatsTable.connect() as stats_table:\n",
    "    data = stats_table.summaries(\n",
    "        aoi=feature,\n",
    "        spatial_join_method=\"touches\",\n",
    "        fields=stats_table.fields(),\n",
    "        geometry=\"polygon\",\n",
    "    )\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess s3 csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"geometry\"] = df[\"geometry\"].apply(lambda geom: from_geojson(geom))\n",
    "df['geometry'] = df['geometry'].apply(lambda geom: shape(geom))\n",
    "gdf = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "# gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(\"kenya_from_db.geojson\", driver=\"GeoJSON\")\n",
    "# gdf = gpd.read_file(\"kenya_from_db.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gdf.explore(\n",
    "    column='sum_pop_m_30_2020',\n",
    "    tooltip='sum_pop_m_30_2020',\n",
    "    cmap='YlGnBu',\n",
    "    legend=True,\n",
    "    scheme='naturalbreaks',\n",
    "    legend_kwds=dict(colorbar=True, caption='Population', interval=False),\n",
    "    style_kwds=dict(weight=0, fillOpacity=0.8),\n",
    "    name='Population by Hexagon'\n",
    ")\n",
    "flm.LayerControl('topright', collapsed = False).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From S3 Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parquet_file = join(expanduser(\"~\"), \"Downloads\", \"m_30_2020.parquet\")\n",
    "parquet_file = \"s3://wbg-geography01/Space2Stats/parquet/GLOBAL/WorldPop_2020_Demographics/m_30_2020.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.read_parquet(parquet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_.loc[df_['SUM']>-1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_s3 = gdf.merge(df_, left_on='hex_id', right_on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gdf_s3.explore(\n",
    "    column='SUM',\n",
    "    tooltip='SUM',\n",
    "    cmap='YlGnBu',\n",
    "    legend=True,\n",
    "    scheme='naturalbreaks',\n",
    "    legend_kwds=dict(colorbar=True, caption='Population', interval=False),\n",
    "    style_kwds=dict(weight=0, fillOpacity=0.8),\n",
    "    name='Population by Hexagon'\n",
    ")\n",
    "flm.LayerControl('topright', collapsed = False).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerun Local ZS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import basename\n",
    "import rasterio as rio\n",
    "from rasterstats import zonal_stats\n",
    "from rasterio import features\n",
    "from affine import Affine\n",
    "from rasterio.plot import show\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input raster variables\n",
    "population_folder = (\n",
    "    \"J://Data/GLOBAL/Population/WorldPop_PPP_2020/GLOBAL_1km_Demographics\"\n",
    ")\n",
    "pop_files = [\n",
    "    os.path.join(population_folder, x)\n",
    "    for x in os.listdir(population_folder)\n",
    "    if x.endswith(\"1km.tif\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_zs = gdf[['hex_id', 'geometry']].copy()\n",
    "geom = adm_boundaries.geometry.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pop_file in tqdm(pop_files):\n",
    "    with rio.open(pop_file) as src:\n",
    "\n",
    "        var_name = basename(pop_file.strip(\"_1km.tif\"))\n",
    "        var_name = var_name.strip('global_')\n",
    "        var_name = 'sum_pop_'+var_name\n",
    "\n",
    "        window = features.geometry_window(src, [geom])\n",
    "        ul_y = window.col_off\n",
    "        lr_x = window.row_off\n",
    "        t = src.transform\n",
    "        affine_wp = Affine(t.a, t.b, t.c+ul_y*t.a, t.d, t.e, t.f+lr_x*t.e)\n",
    "        data = src.read(1, window=window)\n",
    "\n",
    "        zs = zonal_stats(\n",
    "            gdf_zs,\n",
    "            data,\n",
    "            affine=affine_wp,\n",
    "            stats=\"sum\",\n",
    "            nodata=src.nodata\n",
    "        )\n",
    "        gdf_zs = gdf_zs.join(pd.DataFrame(zs).rename(columns={\"sum\": var_name}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_zs.loc[:, \"sum_pop_2020_calc_zs\"] = gdf_zs[['sum_pop_f_0_2020', 'sum_pop_f_10_2020', 'sum_pop_f_15_2020',\n",
    "       'sum_pop_f_1_2020', 'sum_pop_f_20_2020', 'sum_pop_f_25_2020',\n",
    "       'sum_pop_f_30_2020', 'sum_pop_f_35_2020', 'sum_pop_f_40_2020',\n",
    "       'sum_pop_f_45_2020', 'sum_pop_f_50_2020', 'sum_pop_f_55_2020',\n",
    "       'sum_pop_f_5_2020', 'sum_pop_f_60_2020', 'sum_pop_f_65_2020',\n",
    "       'sum_pop_f_70_2020', 'sum_pop_f_75_2020', 'sum_pop_f_80_2020',\n",
    "       'sum_pop_m_0_2020', 'sum_pop_m_10_2020', 'sum_pop_m_15_2020',\n",
    "       'sum_pop_m_1_2020', 'sum_pop_m_20_2020', 'sum_pop_m_25_2020',\n",
    "       'sum_pop_m_30_2020', 'sum_pop_m_35_2020', 'sum_pop_m_40_2020',\n",
    "       'sum_pop_m_45_2020', 'sum_pop_m_50_2020', 'sum_pop_m_55_2020',\n",
    "       'sum_pop_m_5_2020', 'sum_pop_m_60_2020', 'sum_pop_m_65_2020',\n",
    "       'sum_pop_m_70_2020', 'sum_pop_m_75_2020', 'sum_pop_m_80_2020']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_zs.to_file(\"kenya_zs_local.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_zs = gpd.read_file(\"kenya_zs_local.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gdf_zs.explore(\n",
    "    column='sum_pop_m_30_2020',\n",
    "    tooltip='sum_pop_m_30_2020',\n",
    "    cmap='YlGnBu',\n",
    "    legend=True,\n",
    "    scheme='naturalbreaks',\n",
    "    legend_kwds=dict(colorbar=True, caption='Population', interval=False),\n",
    "    style_kwds=dict(weight=0, fillOpacity=0.8),\n",
    "    name='Population by Hexagon'\n",
    ")\n",
    "flm.LayerControl('topright', collapsed = False).add_to(m)\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
