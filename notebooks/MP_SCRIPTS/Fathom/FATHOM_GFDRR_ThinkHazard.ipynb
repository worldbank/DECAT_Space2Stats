{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97304a66",
   "metadata": {},
   "source": [
    "# Flood summaries for ThinkHazard\n",
    "\n",
    "This script performs flood hazard ranking by administrative unit using global-extent\n",
    "Fathom tiles hosted on AWS S3, rather than country-extent locally downloaded data.\n",
    "\n",
    "The hazard ranking is based on:\n",
    "- Value threshold: Minimum flood depth (cm) to consider\n",
    "- Area threshold: Minimum percentage of area affected\n",
    "- Hazard score: Count of return periods meeting both thresholds (0-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e079370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os, time, io, json, sys\n",
    "import urllib3\n",
    "import boto3\n",
    "import h3ronpy\n",
    "import rasterio\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium as flm\n",
    "import matplotlib.pyplot as plt\n",
    "import GOSTrocks.rasterMisc as rMisc\n",
    "import GOSTrocks.dataMisc as dMisc\n",
    "import GOSTrocks.mapMisc as mapMisc\n",
    "\n",
    "from functools import reduce\n",
    "from GOSTrocks.misc import tPrint\n",
    "from h3ronpy.pandas.vector import geodataframe_to_cells, cells_dataframe_to_geodataframe\n",
    "from h3ronpy import ContainmentMode\n",
    "from dotenv import load_dotenv\n",
    "from shapely.geometry import shape, box\n",
    "#from geojson_pydantic import Feature, Polygon\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "from pystac_client import Client\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Import helper functions\n",
    "from gfdrr_helper import *\n",
    "\n",
    "sys.path.append(\"../../src\")\n",
    "\n",
    "import global_zonal\n",
    "import h3_helper\n",
    "\n",
    "urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "def tPrint(s):\n",
    "    \"\"\"prints the time along with the message\"\"\"\n",
    "    print(\"%s\\t%s\" % (time.strftime(\"%H:%M:%S\"), s))\n",
    "\n",
    "s3_client = boto3.client('s3', verify=False, config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "272d06c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_folder = \"C:/WBG/Work/Projects/ThinkHazard\"\n",
    "out_folder = os.path.join(local_folder, \"FATHOM_summaries\")\n",
    "map_folder = os.path.join(local_folder, \"FATHOM_maps\")\n",
    "for tF in [out_folder, map_folder]:\n",
    "    if not os.path.exists(tF):\n",
    "        os.makedirs(tF)\n",
    "vrt_folder = r\"C:\\WBG\\Work\\data\\FATHOM\"\n",
    "s3_bucket = \"wbg-geography01\"\n",
    "s3_prefix = \"FATHOM\"\n",
    "return_periods = [10, 100, 500, 1000]\n",
    "flood_files = [\n",
    "    [\"FU\", \"FLOOD_MAP-1ARCSEC-NW_OFFSET-1in{rp}-FLUVIAL-UNDEFENDED-DEPTH-2020-PERCENTILE50-v3.1.vrt\"],\n",
    "    [\"CU\", \"FLOOD_MAP-1ARCSEC-NW_OFFSET-1in{rp}-COASTAL-UNDEFENDED-DEPTH-2020-PERCENTILE50-v3.1.vrt\"],\n",
    "    ['PD', \"FLOOD_MAP-1ARCSEC-NW_OFFSET-1in{rp}-PLUVIAL-DEFENDED-DEPTH-2020-PERCENTILE50-v3.1.vrt\"]\n",
    "]\n",
    "\n",
    "admin_boundaries_file = r\"C:\\WBG\\Work\\data\\ADMIN\\NEW_WB_BOUNDS\\FOR_PUBLICATION\\crs_4326\\parquet\\WB_GAD_ADM2.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abe361cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISO_A3</th>\n",
       "      <th>ISO_A2</th>\n",
       "      <th>WB_A3</th>\n",
       "      <th>WB_REGION</th>\n",
       "      <th>WB_STATUS</th>\n",
       "      <th>NAM_0</th>\n",
       "      <th>NAM_1</th>\n",
       "      <th>ADM1CD_c</th>\n",
       "      <th>GEOM_SRCE</th>\n",
       "      <th>geometry</th>\n",
       "      <th>NAM_2</th>\n",
       "      <th>ADM2CD_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUS</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Other</td>\n",
       "      <td>Member State</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australian Capital Territory</td>\n",
       "      <td>AUS002</td>\n",
       "      <td>WB GAD</td>\n",
       "      <td>POLYGON ((149.2007 -35.20541, 149.20589 -35.21...</td>\n",
       "      <td>Unincorporated ACT</td>\n",
       "      <td>AUS002001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUS</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Other</td>\n",
       "      <td>Member State</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Other Territories</td>\n",
       "      <td>AUS006</td>\n",
       "      <td>WB GAD</td>\n",
       "      <td>MULTIPOLYGON (((150.76958 -35.1223, 150.76522 ...</td>\n",
       "      <td>Unincorp. Other Territories</td>\n",
       "      <td>AUS006001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUS</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Other</td>\n",
       "      <td>Member State</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>AUS004</td>\n",
       "      <td>WB GAD</td>\n",
       "      <td>POLYGON ((151.15052 -33.8721, 151.14489 -33.88...</td>\n",
       "      <td>Ashfield (A)</td>\n",
       "      <td>AUS004003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUS</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Other</td>\n",
       "      <td>Member State</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>AUS004</td>\n",
       "      <td>WB GAD</td>\n",
       "      <td>POLYGON ((151.08142 -33.84999, 151.07837 -33.8...</td>\n",
       "      <td>Auburn (C)</td>\n",
       "      <td>AUS004004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUS</td>\n",
       "      <td>AU</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Other</td>\n",
       "      <td>Member State</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>AUS004</td>\n",
       "      <td>WB GAD</td>\n",
       "      <td>POLYGON ((151.01316 -33.87841, 151.02907 -33.8...</td>\n",
       "      <td>Bankstown (C)</td>\n",
       "      <td>AUS004007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ISO_A3 ISO_A2 WB_A3 WB_REGION     WB_STATUS      NAM_0  \\\n",
       "0    AUS     AU   AUS     Other  Member State  Australia   \n",
       "1    AUS     AU   AUS     Other  Member State  Australia   \n",
       "2    AUS     AU   AUS     Other  Member State  Australia   \n",
       "3    AUS     AU   AUS     Other  Member State  Australia   \n",
       "4    AUS     AU   AUS     Other  Member State  Australia   \n",
       "\n",
       "                          NAM_1 ADM1CD_c GEOM_SRCE  \\\n",
       "0  Australian Capital Territory   AUS002    WB GAD   \n",
       "1             Other Territories   AUS006    WB GAD   \n",
       "2               New South Wales   AUS004    WB GAD   \n",
       "3               New South Wales   AUS004    WB GAD   \n",
       "4               New South Wales   AUS004    WB GAD   \n",
       "\n",
       "                                            geometry  \\\n",
       "0  POLYGON ((149.2007 -35.20541, 149.20589 -35.21...   \n",
       "1  MULTIPOLYGON (((150.76958 -35.1223, 150.76522 ...   \n",
       "2  POLYGON ((151.15052 -33.8721, 151.14489 -33.88...   \n",
       "3  POLYGON ((151.08142 -33.84999, 151.07837 -33.8...   \n",
       "4  POLYGON ((151.01316 -33.87841, 151.02907 -33.8...   \n",
       "\n",
       "                         NAM_2   ADM2CD_c  \n",
       "0           Unincorporated ACT  AUS002001  \n",
       "1  Unincorp. Other Territories  AUS006001  \n",
       "2                 Ashfield (A)  AUS004003  \n",
       "3                   Auburn (C)  AUS004004  \n",
       "4                Bankstown (C)  AUS004007  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inA = gpd.read_parquet(admin_boundaries_file)\n",
    "inA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6bbb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:30:15\tFile already exists for AUS, skipping...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m     all_res_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(out_file)\n\u001b[0;32m     21\u001b[0m     map_adm \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(sel_a, all_res_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADM2CD_c\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m \u001b[43mmap_flood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmap_adm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmap_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mflood_map_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msel_country\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_100yr.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\WBG\\Work\\Code\\DECAT_Space2Stats\\notebooks\\MP_SCRIPTS\\Fathom\\gfdrr_helper.py:11\u001b[0m, in \u001b[0;36mmap_flood\u001b[1;34m(mapD, return_period, out_file)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_flood\u001b[39m(mapD, return_period, out_file):\n\u001b[1;32m---> 11\u001b[0m     fig, axes \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m     12\u001b[0m     flood_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrac_area_flooded_CU_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_period\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124myr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrac_area_flooded_FU_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_period\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124myr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrac_area_flooded_PD_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_period\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124myr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     13\u001b[0m     flood_titles \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoastal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFluvial\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPluvial\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "with rasterio.Env(GDAL_HTTP_UNSAFESSL='YES'):\n",
    "    for sel_country in inA['ISO_A3'].unique():\n",
    "        all_res = []\n",
    "        out_file = os.path.join(out_folder, f\"FATHOM_ThinkHazard_summary_{sel_country}.csv\")\n",
    "        sel_a = inA[inA['ISO_A3'] == sel_country]                           \n",
    "        if not os.path.exists(out_file) and not (sel_country in [\"FJI\"]):\n",
    "            tPrint(f\"Processing country: {sel_country}\")\n",
    "            for lbl, raster_file in flood_files:\n",
    "                for return_period in return_periods:\n",
    "                    tPrint(f\"Processing {lbl} for {return_period} year return period\")\n",
    "                    sel_raster_file = raster_file.format(rp=return_period)\n",
    "                    sel_raster = f\"s3://{s3_bucket}/{s3_prefix}/{sel_raster_file}\"\n",
    "                    res_a = calculate_think_hazard_score(sel_a, sel_raster, depth_threshold=50, idx_col='ADM2CD_c')\n",
    "                    res_a.rename(columns={'frac_area_flooded': f'frac_area_flooded_{lbl}_{return_period}yr'}, inplace=True)\n",
    "                    all_res.append(res_a)\n",
    "            all_res_df = reduce(lambda left, right: pd.merge(left, right, on='ADM2CD_c', how='outer'), all_res) \n",
    "            all_res_df.to_csv(out_file, index=False)\n",
    "        else:\n",
    "            tPrint(f\"File already exists for {sel_country}, skipping...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab6c6fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/WBG/Work/Projects/ThinkHazard\\\\FATHOM_summaries\\\\FATHOM_ThinkHazard_summary_FJI.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sel_country \u001b[38;5;129;01min\u001b[39;00m inA[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mISO_A3\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[0;32m      3\u001b[0m     out_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(out_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFATHOM_ThinkHazard_summary_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msel_country\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     all_res_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     sel_a \u001b[38;5;241m=\u001b[39m inA[inA[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mISO_A3\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m sel_country]                                   \n\u001b[0;32m      6\u001b[0m     map_adm \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(sel_a, all_res_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADM2CD_c\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\WBG\\Anaconda3\\envs\\s2s_ingest\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\WBG\\Anaconda3\\envs\\s2s_ingest\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\WBG\\Anaconda3\\envs\\s2s_ingest\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\WBG\\Anaconda3\\envs\\s2s_ingest\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\WBG\\Anaconda3\\envs\\s2s_ingest\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/WBG/Work/Projects/ThinkHazard\\\\FATHOM_summaries\\\\FATHOM_ThinkHazard_summary_FJI.csv'"
     ]
    }
   ],
   "source": [
    "# Map floods for all results\n",
    "for sel_country in tqdm(inA['ISO_A3'].unique()):\n",
    "    out_file = os.path.join(out_folder, f\"FATHOM_ThinkHazard_summary_{sel_country}.csv\")\n",
    "    try:\n",
    "        all_res_df = pd.read_csv(out_file)\n",
    "        sel_a = inA[inA['ISO_A3'] == sel_country]                                   \n",
    "        map_adm = pd.merge(sel_a, all_res_df, on='ADM2CD_c', how='left')\n",
    "        map_flood(map_adm, return_period=100, out_file=os.path.join(map_folder, f\"flood_map_{sel_country}_100yr.png\"))\n",
    "    except FileNotFoundError:\n",
    "        tPrint(f\"No summary file for {sel_country}, skipping mapping...\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af6b7b9",
   "metadata": {},
   "source": [
    "# DEBURRGGGGINININING\n",
    "In the initial run there is an error in the coastal processing, this section opens all those files and re-processes the coastal flood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a38f14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b63bae6cb214742957c8623efd31019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get a list of all processed countries\n",
    "processed_countries = [f.split(\"_\")[-1].split(\".\")[0] for f in os.listdir(out_folder) if f.startswith(\"FATHOM_ThinkHazard_summary_\")]\n",
    "\n",
    "for sel_country in tqdm(processed_countries):    \n",
    "    sel_a = inA[inA['ISO_A3'] == sel_country]    \n",
    "    lbl, raster_file = flood_files[1]\n",
    "    existing_file = os.path.join(out_folder, f\"FATHOM_ThinkHazard_summary_{sel_country}.csv\")\n",
    "    existing_df = pd.read_csv(existing_file)\n",
    "        \n",
    "    for return_period in return_periods:\n",
    "        sel_raster_file = raster_file.format(rp=return_period)\n",
    "        sel_raster = f\"s3://{s3_bucket}/{s3_prefix}/{sel_raster_file}\"\n",
    "        with rasterio.Env(GDAL_HTTP_UNSAFESSL='YES'):\n",
    "            with rasterio.open(sel_raster) as inR:            \n",
    "                res_a = calculate_think_hazard_score(sel_a, sel_raster, depth_threshold=50, idx_col='ADM2CD_c')\n",
    "                res_a.rename(columns={'frac_area_flooded': f'frac_area_flooded_{lbl}_{return_period}yr'}, inplace=True)\n",
    "\n",
    "        # Drop coastal flooding column if they exist and add new columns\n",
    "        existing_df = existing_df.drop(columns=[f'frac_area_flooded_{lbl}_{return_period}yr'], errors='ignore')\n",
    "        existing_df = pd.merge(existing_df, res_a, on='ADM2CD_c', how='left')\n",
    "    existing_df.to_csv(existing_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da23d663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/WBG/Work/Projects/ThinkHazard\\\\FATHOM_summaries'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbfe0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_adm = pd.merge(sel_a, res_a, on='ADM2CD_c', how='left')\n",
    "map_adm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92443895",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res_df.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85e4aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_adm = pd.merge(sel_a, all_res_df, on='ADM2CD_c', how='left')\n",
    "for col in all_res_df.columns[1:]:\n",
    "    map_adm['FLOOD_COL'] = (map_adm[col] * 100).fillna(0)\n",
    "    plt = mapMisc.static_map_vector(map_adm, 'FLOOD_COL', thresh=[0, 5, 10, 15, 100], colormap='Blues')\n",
    "    plt.savefig(os.path.join(map_folder, f\"{sel_country}_{col}_map.png\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804750a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapMisc.static_map_vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d1e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7879fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2s_ingest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
