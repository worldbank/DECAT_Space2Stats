{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import rasterio\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, \"c:\\\\WBG\\\\Work\\\\Code\\\\GOSTrocks\\\\src\")\n",
    "import GOSTrocks.dataMisc as dMisc\n",
    "import GOSTrocks.rasterMisc as rMisc\n",
    "\n",
    "sys.path.insert(0, \"../src\")\n",
    "\n",
    "import global_zonal\n",
    "import h3_helper\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_file = \"h1_dictionary_of_h6_geodata_frames.pickle\"\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(h3_1_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "generate_lvl0_lists() got an unexpected keyword argument 'read_pickel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m AWS_SESSION_TOKEN \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAWS_SESSION_TOKEN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m h3_level \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[1;32m----> 7\u001b[0m h3_1_list \u001b[38;5;241m=\u001b[39m h3_helper\u001b[38;5;241m.\u001b[39mgenerate_lvl0_lists(h3_level, return_gdf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, buffer0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, read_pickel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m pop_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mWBG\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mWork\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPOP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mppp_2020_1km_Aggregated.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m in_pop \u001b[38;5;241m=\u001b[39m rasterio\u001b[38;5;241m.\u001b[39mopen(pop_layer)\n",
      "\u001b[1;31mTypeError\u001b[0m: generate_lvl0_lists() got an unexpected keyword argument 'read_pickel'"
     ]
    }
   ],
   "source": [
    "AWS_S3_BUCKET = 'wbg-geography01'\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_SESSION_TOKEN = os.getenv(\"AWS_SESSION_TOKEN\")\n",
    "\n",
    "h3_level = 6\n",
    "h3_1_list = h3_helper.generate_lvl0_lists(h3_level, return_gdf=True, buffer0=False, read_pickle=False)\n",
    "\n",
    "pop_layer = r\"C:\\WBG\\Work\\data\\POP\\ppp_2020_1km_Aggregated.tif\"\n",
    "in_pop = rasterio.open(pop_layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select layer to downlaod\n",
    "flood_type = [\"PLUVIAL\",\"FLUVIAL\",\"COASTAL\"]\n",
    "defence = [\"DEFENDED\"]\n",
    "return_period = ['1in100']\n",
    "climate_model = [\"PERCENTILE50\"]\n",
    "year = [\"2020\"]\n",
    "\n",
    "# all_vrts is a pandas dataframe with all the vrt paths to the global datasets, with columns defining\n",
    "# the various models' defining attributes\n",
    "all_vrts = dMisc.get_fathom_vrts(True)\n",
    "sel_images = all_vrts.loc[(all_vrts['FLOOD_TYPE'].isin(flood_type)) & (all_vrts['DEFENCE'].isin(defence)) & \n",
    "             (all_vrts['RETURN'].isin(return_period))  & (all_vrts['CLIMATE_MODEL'].isin(climate_model))]\n",
    "fathom_vrt_path = sel_images['PATH'].iloc[0]\n",
    "in_fathom = rasterio.open(fathom_vrt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RETURN</th>\n",
       "      <th>FLOOD_TYPE</th>\n",
       "      <th>DEFENCE</th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>CLIMATE_MODEL</th>\n",
       "      <th>PATH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1in100</td>\n",
       "      <td>COASTAL</td>\n",
       "      <td>DEFENDED</td>\n",
       "      <td>DEPTH</td>\n",
       "      <td>2020</td>\n",
       "      <td>PERCENTILE50</td>\n",
       "      <td>s3://wbg-geography01/FATHOM/GLOBAL-1ARCSEC-NW_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1in100</td>\n",
       "      <td>FLUVIAL</td>\n",
       "      <td>DEFENDED</td>\n",
       "      <td>DEPTH</td>\n",
       "      <td>2020</td>\n",
       "      <td>PERCENTILE50</td>\n",
       "      <td>s3://wbg-geography01/FATHOM/GLOBAL-1ARCSEC-NW_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1in100</td>\n",
       "      <td>PLUVIAL</td>\n",
       "      <td>DEFENDED</td>\n",
       "      <td>DEPTH</td>\n",
       "      <td>2020</td>\n",
       "      <td>PERCENTILE50</td>\n",
       "      <td>s3://wbg-geography01/FATHOM/GLOBAL-1ARCSEC-NW_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     RETURN FLOOD_TYPE   DEFENCE  DEPTH  YEAR CLIMATE_MODEL  \\\n",
       "65   1in100    COASTAL  DEFENDED  DEPTH  2020  PERCENTILE50   \n",
       "91   1in100    FLUVIAL  DEFENDED  DEPTH  2020  PERCENTILE50   \n",
       "117  1in100    PLUVIAL  DEFENDED  DEPTH  2020  PERCENTILE50   \n",
       "\n",
       "                                                  PATH  \n",
       "65   s3://wbg-geography01/FATHOM/GLOBAL-1ARCSEC-NW_...  \n",
       "91   s3://wbg-geography01/FATHOM/GLOBAL-1ARCSEC-NW_...  \n",
       "117  s3://wbg-geography01/FATHOM/GLOBAL-1ARCSEC-NW_...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COASTAL_1in100_PERCENTILE50_2020\n",
      "FLUVIAL_1in100_PERCENTILE50_2020\n",
      "PLUVIAL_1in100_PERCENTILE50_2020\n"
     ]
    }
   ],
   "source": [
    "for fathom_index, fathom_row in sel_images.iterrows():\n",
    "    out_file = \"_\".join([fathom_row['FLOOD_TYPE'], fathom_row['RETURN'], fathom_row['CLIMATE_MODEL'], fathom_row['YEAR']])\n",
    "    print(out_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = list(h3_1_list.keys())[0]\n",
    "out_file = f\"C:/WBG/Work/data/zonal_{sample_id}.csv\"\n",
    "reclass_dict = { 0: [-9999, 0], \n",
    "                1: [0, 10], \n",
    "                2: [10.1, 50], \n",
    "                3: [50, 100000.0],}\n",
    "\n",
    "xx = global_zonal.zonal_stats_categorical(h3_1_list[sample_id], \"shape_id\", in_pop, in_fathom, out_file, reclass_dict=reclass_dict, \n",
    "                                          buffer0=True, minVal=0, maxVal=10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C:/WBG/Work/data/zonal_8140fffffffffff.csv':                        0_SUM  0_MIN        0_MAX     0_MEAN         1_SUM  \\\n",
       " id                                                                          \n",
       " 8640d50f7ffffff     0.000000    0.0     0.000000   0.000000   2067.635986   \n",
       " 8640f63a7ffffff     0.000000    0.0     0.000000   0.000000   5794.220215   \n",
       " 8640ce0e7ffffff     0.000000    0.0     0.000000   0.000000     54.516670   \n",
       " 8640d080fffffff     0.000000    0.0     0.000000   0.000000  18001.263672   \n",
       " 8640e26c7ffffff   234.824295    0.0   234.824295   4.996262  22601.615234   \n",
       " ...                      ...    ...          ...        ...           ...   \n",
       " 8640ca7afffffff     0.000000    0.0     0.000000   0.000000     77.144470   \n",
       " 8640d9227ffffff     0.000000    0.0     0.000000   0.000000    201.811218   \n",
       " 8640e3c2fffffff  1834.572021    0.0  1834.572021  39.882000  76966.687500   \n",
       " 8640ced27ffffff     0.000000    0.0     0.000000   0.000000    383.207001   \n",
       " 8640f032fffffff  1725.918579    0.0  1725.918579  38.353745  10400.603516   \n",
       " \n",
       "                  1_MIN        1_MAX       1_MEAN         2_SUM  2_MIN  \\\n",
       " id                                                                      \n",
       " 8640d50f7ffffff    0.0    92.556847    45.947468      0.000000    0.0   \n",
       " 8640f63a7ffffff    0.0   324.454620   128.760452      0.000000    0.0   \n",
       " 8640ce0e7ffffff    0.0     1.670754     1.135764      0.000000    0.0   \n",
       " 8640d080fffffff    0.0  1156.441162   391.331818      0.000000    0.0   \n",
       " 8640e26c7ffffff    0.0  2029.754395   480.885437   1480.808228    0.0   \n",
       " ...                ...          ...          ...           ...    ...   \n",
       " 8640ca7afffffff    0.0     2.829504     1.574377      3.457746    0.0   \n",
       " 8640d9227ffffff    0.0     8.921992     4.586618      0.000000    0.0   \n",
       " 8640e3c2fffffff    0.0  7131.542969  1673.188843  12783.718750    0.0   \n",
       " 8640ced27ffffff    0.0    18.058975     8.330587     12.162897    0.0   \n",
       " 8640f032fffffff    0.0   950.360168   231.124527      0.000000    0.0   \n",
       " \n",
       "                        2_MAX      2_MEAN         3_SUM  3_MIN        3_MAX  \\\n",
       " id                                                                           \n",
       " 8640d50f7ffffff     0.000000    0.000000     55.941162    0.0    55.941162   \n",
       " 8640f63a7ffffff     0.000000    0.000000    295.815430    0.0   154.801208   \n",
       " 8640ce0e7ffffff     0.000000    0.000000      2.155113    0.0     1.103793   \n",
       " 8640d080fffffff     0.000000    0.000000   2949.641113    0.0   898.040405   \n",
       " 8640e26c7ffffff   675.422302   31.506557    753.313354    0.0   557.013184   \n",
       " ...                      ...         ...           ...    ...          ...   \n",
       " 8640ca7afffffff     2.269154    0.070566      3.302973    0.0     1.734814   \n",
       " 8640d9227ffffff     0.000000    0.000000     11.800947    0.0     6.409394   \n",
       " 8640e3c2fffffff  2989.082031  277.906921  17843.751953    0.0  5467.551270   \n",
       " 8640ced27ffffff    12.162897    0.264411      0.000000    0.0     0.000000   \n",
       " 8640f032fffffff     0.000000    0.000000      0.000000    0.0     0.000000   \n",
       " \n",
       "                      3_MEAN  \n",
       " id                           \n",
       " 8640d50f7ffffff    1.243137  \n",
       " 8640f63a7ffffff    6.573676  \n",
       " 8640ce0e7ffffff    0.044898  \n",
       " 8640d080fffffff   64.122635  \n",
       " 8640e26c7ffffff   16.027945  \n",
       " ...                     ...  \n",
       " 8640ca7afffffff    0.067408  \n",
       " 8640d9227ffffff    0.268203  \n",
       " 8640e3c2fffffff  387.907654  \n",
       " 8640ced27ffffff    0.000000  \n",
       " 8640f032fffffff    0.000000  \n",
       " \n",
       " [16807 rows x 16 columns]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_zonal.zonal_stats_numerical()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip and extract the input datasets\n",
    "out_folder = \"C:/WBG/Work/S2S/data/FATHOM_TESTING\"\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "\n",
    "out_fathom = os.path.join(out_folder, f\"fathom_{sample_id}.tif\")\n",
    "out_pop = os.path.join(out_folder, f\"pop_{sample_id}.tif\")\n",
    "out_h3 = os.path.join(out_folder, f\"h3_{sample_id}.geojson\")\n",
    "if not os.path.exists(out_h3):\n",
    "    h3_1_list[sample_id].to_file(out_h3, driver='GeoJSON')\n",
    "\n",
    "if not os.path.exists(out_pop):\n",
    "    rMisc.clipRaster(in_pop, h3_1_list[sample_id], out_pop)\n",
    "\n",
    "if not os.path.exists(out_fathom):\n",
    "    temp_p = rasterio.open(out_pop)\n",
    "    rMisc.standardizeInputRasters(in_fathom, temp_p, out_fathom)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `rMisc.clipRaster` not found.\n"
     ]
    }
   ],
   "source": [
    "rMisc.clipRaster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clip and extract the input datasets\n",
    "out_folder = \"C:/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urban_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
